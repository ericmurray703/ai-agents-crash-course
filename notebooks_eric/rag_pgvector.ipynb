{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6352216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Document Embedding Pipeline with LlamaIndex + PostgreSQL\n",
    "# A streamlined RAG pipeline using LlamaIndex with pgvector\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Setup\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from sqlalchemy import make_url\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.readers.web import SimpleWebPageReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9dc3996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06fa03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure global settings\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.llm = OpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22fc455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection\n",
    "connection_string = \"postgresql://eric:pOs11Nut#@192.168.68.95:5432/vectordb\"\n",
    "url = make_url(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3a5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pgvector store\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=url.database,\n",
    "    host=url.host,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    password=url.password,\n",
    "    table_name=\"documents\",\n",
    "    embed_dim=1536,  # text-embedding-3-small dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ec5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda10392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78a56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pdf(file_path: str):\n",
    "    \"\"\"Add a PDF file to the index.\"\"\"\n",
    "    from llama_index.readers.file import PDFReader\n",
    "    \n",
    "    reader = PDFReader()\n",
    "    docs = reader.load_data(file_path)\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = file_path\n",
    "    \n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents(docs))\n",
    "    print(f\"Added {len(docs)} pages from {file_path}\")\n",
    "\n",
    "\n",
    "def add_url(url: str):\n",
    "    \"\"\"Add a web page to the index.\"\"\"\n",
    "    reader = SimpleWebPageReader(html_to_text=True)\n",
    "    docs = reader.load_data([url])\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = url\n",
    "    \n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents(docs))\n",
    "    print(f\"Added content from {url}\")\n",
    "    \n",
    "def add_text(text: str, source: str = \"manual\"):\n",
    "    \"\"\"Add raw text to the index.\"\"\"\n",
    "    doc = Document(text=text, metadata={\"source\": source})\n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents([doc]))\n",
    "    print(f\"Added text from {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fab3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added text from test\n"
     ]
    }
   ],
   "source": [
    "# Test with raw text\n",
    "add_text(\"\"\"PostgreSQL is an open source relational database. \n",
    "pgvector adds vector similarity search capabilities to PostgreSQL.\"\"\",\n",
    "source=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a3cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:37:47,787 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 pages from ./data/Eric_Murray_Resume_2025.pdf\n"
     ]
    }
   ],
   "source": [
    "add_pdf('./data/Eric_Murray_Resume_2025.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d040af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Query the Index\n",
    "\n",
    "# %%\n",
    "def search(query: str, top_k: int = 5):\n",
    "    \"\"\"Search for similar documents.\"\"\"\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    nodes = retriever.retrieve(query)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    for i, node in enumerate(nodes):\n",
    "        print(f\"--- Result {i+1} (score: {node.score:.4f}) ---\")\n",
    "        print(f\"Source: {node.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"Preview: {node.text[:300]}...\\n\")\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "\n",
    "# Create query engine\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "def ask(question: str):\n",
    "    \"\"\"Ask a question and get an answer based on indexed documents.\"\"\"\n",
    "    response = query_engine.query(question)\n",
    "    \n",
    "    print(f\"Question: {question}\\n\")\n",
    "    print(f\"Answer: {response.response}\\n\")\n",
    "    print(\"Sources:\")\n",
    "    for node in response.source_nodes:\n",
    "        print(f\"  - {node.metadata.get('source', 'Unknown')} (score: {node.score:.4f})\")\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "744501ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:37:51,553 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: PostgreSQL\n",
      "\n",
      "--- Result 1 (score: 0.6483) ---\n",
      "Source: test\n",
      "Preview: PostgreSQL is an open source relational database. \n",
      "pgvector adds vector similarity search capabilities to PostgreSQL....\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='de33699e-760a-4875-a158-87d3185276a2', embedding=None, metadata={'source': 'test'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='13dabb6a-00e5-4df1-8998-5f168bf990e0', node_type='4', metadata={'source': 'test'}, hash='6eab3b67283d2cba4e829670d8eaf3fa68188d076c3d53f3cddd62e1821e7769')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='PostgreSQL is an open source relational database. \\npgvector adds vector similarity search capabilities to PostgreSQL.', mimetype='text/plain', start_char_idx=0, end_char_idx=117, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6482917489657701)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test search\n",
    "search(\"PostgreSQL\", 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a89eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:38:18,943 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-12-06 11:38:22,624 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Has Eric ever worked at Eyes Only Systems?\n",
      "\n",
      "Answer: Yes — he was Vice President / Co-Founder at Eyes Only Systems in Reston, VA from 2013 to 2017.\n",
      "\n",
      "Sources:\n",
      "  - ./data/Eric_Murray_Resume_2025.pdf (score: 0.4468)\n",
      "  - ./data/Eric_Murray_Resume_2025.pdf (score: 0.3335)\n",
      "  - test (score: 0.1044)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='Yes — he was Vice President / Co-Founder at Eyes Only Systems in Reston, VA from 2013 to 2017.', source_nodes=[NodeWithScore(node=TextNode(id_='3cee2f44-f97b-4d06-b226-1d25cc562a5d', embedding=None, metadata={'page_label': '2', 'file_name': 'Eric_Murray_Resume_2025.pdf', 'source': './data/Eric_Murray_Resume_2025.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f6c514fe-371b-45ad-8de7-25b18af43950', node_type='4', metadata={'page_label': '2', 'file_name': 'Eric_Murray_Resume_2025.pdf', 'source': './data/Eric_Murray_Resume_2025.pdf'}, hash='203f03f73c16fdae37bc57f516c817deea952cf0c0e11dfb340c924a999e2fd8')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='●  Managed  cross-functional  teams  (4-8  members)  for  data  science  implementation  and  platform  \\ndeployment\\n \\n ●  Delivered  measurable  operational  improvements  earning  promotion  based  on  performance   \\nTechnical  Director,  Public  Sector  |  Jun  2017  –  Oct  2018,  Dec  2019  –  May  2021   ●  Led  government-focused  initiatives  and  technical  sales  efforts  for  Topological  Data  Analysis  in  \\nDefense\\n \\nand\\n \\nManufacturing\\n \\nacross\\n \\nseven\\n \\nSymphony\\n \\nportfolio\\n \\ncompanies\\n \\n ●  Partnered  with  sales  teams  delivering  strategic  demos  and  aligning  platform  capabilities  with  \\ncustomer\\n \\nmissions\\n \\n \\nC3.AI  |  McLean,  VA  |  Oct  2018  –  Dec  2019   Forward  Deployed  Solutions  Engineer   ●  Partnered  with  enterprise  customers  translating  requirements  into  detailed  product  definitions  \\nand\\n \\nMVP\\n \\ndevelopment\\n ●  Served  as  technical  expert  during  customer  engagements  supporting  complex  sales  cycles  \\nEYES  ONLY  SYSTEMS  |  Reston,  VA  |  2013  –  2017   Vice  President  /  Co-Founder  ●  Co-founded  software  startup  targeting  government  and  law  enforcement  markets,  leading  \\nproduct\\n \\nvision\\n \\nand\\n \\nengineering\\n ●  Secured  beta  testing  agreements  with  DHS  and  state  law  enforcement  agencies  \\nEARLY  CAREER  PROGRESSION  |  2000  –  2013   Scaled  operations  and  led  technical  initiatives  across  Apogee  Integration  (COO/VP  Services) ,  \\nRaytheon\\n \\n(Program\\n \\nManager)\\n,\\n \\nand\\n \\nengineering\\n \\nroles\\n \\nat\\n \\nBAE\\n \\nSystems,\\n \\nAnalytical\\n \\nGraphics,\\n \\nand\\n \\nAdroit\\n \\nSystems\\n.\\n \\nKEY  ACHIEVEMENTS   Microsoft  Partner  of  the  Year  –  Contributing  leader  for  SymphonyAI  Financial  Services  \\nrecognition\\n \\n(2024)\\n \\n \\nSuperstar\\n \\nin\\n \\nAI\\n \\n–\\n \\nSymphonyAI\\n \\nindividual\\n \\nrecognition\\n \\n(2023)\\n \\n \\nNational\\n \\nIntelligence\\n \\nCitations\\n \\n–\\n \\nMcCone\\n \\nTechnical\\n \\nAward\\n \\n(CIA\\n \\nDS&T)\\n \\nand\\n \\nMeritorious\\n \\nUnit\\n \\nCitation\\n \\n(DNI)\\n \\n \\nEntrepreneurial\\n \\nSuccess\\n \\n–\\n \\nCo-founded\\n \\nstartup\\n \\nwith\\n \\nDHS\\n \\npartnerships\\n \\nand\\n \\ngovernment\\n \\ncontracts\\n \\n \\nPlatform\\n \\nMigration\\n \\nLeadership\\n \\n–\\n \\nSuccessfully\\n \\ntransitioning\\n \\nlarge\\n \\ntier-one\\n \\nfinancial\\n \\ninstitutions\\n \\nto\\n \\nnext-generation\\n \\nAI\\n \\nplatform\\n \\n \\nEDUCATION  &  CREDENTIALS   Master  of  Engineering  |  North  Carolina  State  University  (2002-2005)   \\nBachelor\\n \\nof\\n \\nScience,\\n \\nMechanical\\n \\nEngineering\\n \\n|\\n \\nUniversity\\n \\nof\\n \\nVirginia\\n \\n(1996-2000)', mimetype='text/plain', start_char_idx=0, end_char_idx=2412, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4467900826570419), NodeWithScore(node=TextNode(id_='130ea9aa-38cf-4732-83c3-7000534466c3', embedding=None, metadata={'page_label': '1', 'file_name': 'Eric_Murray_Resume_2025.pdf', 'source': './data/Eric_Murray_Resume_2025.pdf'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='96d881af-6092-4581-858d-c7a0a23fb467', node_type='4', metadata={'page_label': '1', 'file_name': 'Eric_Murray_Resume_2025.pdf', 'source': './data/Eric_Murray_Resume_2025.pdf'}, hash='05c250c6cec61de382e01eb69e41e7a6c00c10029962cab5daf70dd7fe381af7')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='ERIC  MURRAY  \\nProduct  Director  -  AI  Platform  Strategy  &  Go-to-Market  Leadership   ericmurray703@gmail.com  |  703-397-3110  |  Nashville,  TN  | link edin.com/in/ericmurr a yAI  \\nEXECUTIVE  SUMMARY   Strategic  AI  platform  leader  with  25+  years  driving  innovation  across  Financial  Services,  \\nGovernment,\\n \\nand\\n \\nHigh-Tech\\n \\nindustries.\\n \\nProven\\n \\nexpertise\\n \\nbuilding\\n \\nand\\n \\nscaling\\n \\nAI\\n \\nproducts\\n \\nfrom\\n \\nconcept\\n \\nthrough\\n \\nenterprise\\n \\nadoption,\\n \\nwith\\n \\nGTM\\n \\nstrategy,\\n \\ncustomer\\n \\ndiscovery,\\n \\nand\\n \\ncross-functional\\n \\nleadership\\n \\nexperience.\\n \\nCurrently\\n \\nleading\\n \\nGenAI\\n \\nplatform\\n \\ndevelopment\\n \\nserving\\n \\nlarge\\n \\ntier-one\\n \\nfinancial\\n \\ninstitutions\\n \\nwith\\n \\ndemonstrated\\n \\nsuccess\\n \\ntranslating\\n \\ncomplex\\n \\nAI\\n \\ncapabilities\\n \\ninto\\n \\nmarket-ready\\n \\nsolutions\\n \\nthat\\n \\ndrive\\n \\noperational\\n \\nefficiency.\\n \\nSTRATEGIC  COMPETENCIES Go-to-Market  &  Sales  Leadership  Platform  Strategy  &  Roadmap  |  Market  Analysis  |  Customer  Discovery  |  Complex  B2B  Sales  Cycles  |  \\nC-Suite\\n \\nPresentations\\n \\n|\\n \\nStrategic\\n \\nPartnerships\\n \\n|\\n \\nRevenue\\n \\nGrowth\\n \\nStrategy\\n \\nAI  Platform  Development  Generative  AI  Solutions  |  Agent  Orchestration  |  Data  Science  &  Analytics  |  MVP  Development  |  \\nProduct-Market\\n \\nFit\\n \\n|\\n \\nCross-functional\\n \\nTeam\\n \\nLeadership\\n \\nOperational  Excellence  &  Market  Engagement  Process  Automation  |  Workflow  Optimization  |  Industry  Evangelism  |  Strategic  Demos  |  PoC  \\nExecution\\n \\n|\\n \\nStakeholder\\n \\nAlignment\\n \\nLEADERSHIP  EXPERIENCE  SYMPHONYAI  |  SF,  CA  (Remote)  |  Jun  2017  –  Oct  2018,  Dec  2019  –  Present  Product  Director  –  Generative  AI,  Financial  Services  |  Jun  2023  –  Present   ●  Leading  development  of  breakthrough  GenAI  solutions:  Case  Manager  (GA)  and  Agent  Platform  \\n(MVP)\\n \\nwith\\n \\norchestration\\n \\nengine\\n \\n ●  Driving  comprehensive  GTM  strategy  from  requirements  gathering  through  engineering  \\nexecution\\n \\naligned\\n \\nwith\\n \\nsales\\n \\nobjectives\\n \\n ●  Engaging  and  driving  complex  sales  cycles  with  tier-one  institutions  including  C-suite  \\npresentations\\n \\nat\\n \\nVisa\\n \\nand\\n \\nMorgan\\n \\nStanley\\n \\n ●  Key  contributor  to  SymphonyAI  Financial  Services  earning  Microsoft  Partner  of  the  Year  (2024)   \\nVice  President,  Technical  Services  |  May  2021  –  Jun  2023   ●  Led  customer  success  and  technical  delivery  operations,  driving  operational  efficiency  through  \\nAI-powered\\n \\nworkflow\\n \\nautomation', mimetype='text/plain', start_char_idx=0, end_char_idx=2469, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3335413336753845), NodeWithScore(node=TextNode(id_='de33699e-760a-4875-a158-87d3185276a2', embedding=None, metadata={'source': 'test'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='13dabb6a-00e5-4df1-8998-5f168bf990e0', node_type='4', metadata={'source': 'test'}, hash='6eab3b67283d2cba4e829670d8eaf3fa68188d076c3d53f3cddd62e1821e7769')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='PostgreSQL is an open source relational database. \\npgvector adds vector similarity search capabilities to PostgreSQL.', mimetype='text/plain', start_char_idx=0, end_char_idx=117, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.10440815362881717)], metadata={'3cee2f44-f97b-4d06-b226-1d25cc562a5d': {'page_label': '2', 'file_name': 'Eric_Murray_Resume_2025.pdf', 'source': './data/Eric_Murray_Resume_2025.pdf'}, '130ea9aa-38cf-4732-83c3-7000534466c3': {'page_label': '1', 'file_name': 'Eric_Murray_Resume_2025.pdf', 'source': './data/Eric_Murray_Resume_2025.pdf'}, 'de33699e-760a-4875-a158-87d3185276a2': {'source': 'test'}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Q&A\n",
    "ask(\"Has Eric ever worked at Eyes Only Systems?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Utility Functions\n",
    "\n",
    "# %%\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "def get_stats():\n",
    "    \"\"\"Get collection statistics.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT COUNT(*) FROM data_documents\"))\n",
    "        count = result.scalar()\n",
    "    return {\"total_chunks\": count}\n",
    "\n",
    "\n",
    "def view_all(limit: int = 10):\n",
    "    \"\"\"View stored documents.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(f\"SELECT id, metadata_, text FROM data_documents LIMIT {limit}\"))\n",
    "        rows = result.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        print(f\"ID: {row[0]}\")\n",
    "        print(f\"Metadata: {row[1]}\")\n",
    "        print(f\"Text: {row[2][:200]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "\n",
    "def view_sources():\n",
    "    \"\"\"View unique sources in the database.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT DISTINCT metadata_->>'source' as source FROM data_documents\"))\n",
    "        sources = [row[0] for row in result.fetchall()]\n",
    "    \n",
    "    for source in sources:\n",
    "        print(f\"  - {source}\")\n",
    "    \n",
    "    return sources\n",
    "\n",
    "\n",
    "def delete_by_source(source: str):\n",
    "    \"\"\"Delete all chunks from a specific source.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"DELETE FROM data_documents WHERE metadata_->>'source' = :source\"),\n",
    "            {\"source\": source}\n",
    "        )\n",
    "        conn.commit()\n",
    "    print(f\"Deleted chunks from {source}\")\n",
    "\n",
    "\n",
    "def reset():\n",
    "    \"\"\"Clear all documents from the database.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"TRUNCATE TABLE data_documents\"))\n",
    "        conn.commit()\n",
    "    print(\"Database cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_stats()          # See how many chunks you have\n",
    "# view_sources()       # List all sources\n",
    "# view_all(limit=5)    # Preview stored content\n",
    "# delete_by_source(\"path/to/old.pdf\")  # Remove specific doc\n",
    "# reset()            # Nuclear option - clear everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c9044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted chunks from test\n"
     ]
    }
   ],
   "source": [
    "# delete_by_source(\"test\")  # Remove specific doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c4108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database cleared.\n"
     ]
    }
   ],
   "source": [
    "# reset()            # Nuclear option - clear everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10fef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_chunks': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats()          # See how many chunks you have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ddcb52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_sources()       # List all sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3cf0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_all(limit=5)    # Preview stored content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961f6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
