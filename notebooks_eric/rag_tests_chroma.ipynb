{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64bd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.readers.web import SimpleWebPageReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f297c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e58147b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure global settings\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.llm = OpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=1000, chunk_overlap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c43f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"my_documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2955381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50d6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load index\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527445bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to add documents, directories, etc\n",
    "\n",
    "def add_pdf(file_path: str):\n",
    "    \"\"\"Add a PDF file to the index.\"\"\"\n",
    "    from llama_index.readers.file import PDFReader\n",
    "    \n",
    "    reader = PDFReader()\n",
    "    docs = reader.load_data(file_path)\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = file_path\n",
    "    \n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents(docs))\n",
    "    print(f\"Added {len(docs)} pages from {file_path}\")\n",
    "\n",
    "\n",
    "def add_url(url: str):\n",
    "    \"\"\"Add a web page to the index.\"\"\"\n",
    "    reader = SimpleWebPageReader(html_to_text=True)\n",
    "    docs = reader.load_data([url])\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = url\n",
    "    \n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents(docs))\n",
    "    print(f\"Added content from {url}\")\n",
    "\n",
    "def add_urls(urls: list[str]):\n",
    "    \"\"\"Add multiple web pages to the index.\"\"\"\n",
    "    reader = SimpleWebPageReader(html_to_text=True)\n",
    "    docs = reader.load_data(urls)\n",
    "    \n",
    "    for doc, url in zip(docs, urls):\n",
    "        doc.metadata[\"source\"] = url\n",
    "    \n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents(docs))\n",
    "    print(f\"Added content from {len(urls)} URLs\")\n",
    "\n",
    "\n",
    "def add_text(text: str, source: str = \"manual\"):\n",
    "    \"\"\"Add raw text to the index.\"\"\"\n",
    "    doc = Document(text=text, metadata={\"source\": source})\n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents([doc]))\n",
    "    print(f\"Added text from {source}\")\n",
    "\n",
    "\n",
    "def add_directory(directory_path: str):\n",
    "    \"\"\"Add all supported files from a directory.\"\"\"\n",
    "    reader = SimpleDirectoryReader(directory_path)\n",
    "    docs = reader.load_data()\n",
    "    index.insert_nodes(Settings.node_parser.get_nodes_from_documents(docs))\n",
    "    print(f\"Added {len(docs)} documents from {directory_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe73f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "    \"\"\"Get collection statistics.\"\"\"\n",
    "    return {\n",
    "        \"total_chunks\": chroma_collection.count()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc6fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    \"\"\"Clear all documents from the index.\"\"\"\n",
    "    # Delete and recreate collection\n",
    "    chroma_client.delete_collection(\"my_documents\")\n",
    "    global chroma_collection, vector_store, storage_context, index, query_engine, chat_engine\n",
    "    \n",
    "    chroma_collection = chroma_client.create_collection(\"my_documents\")\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store=vector_store,\n",
    "        storage_context=storage_context,\n",
    "    )\n",
    "    query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "    chat_engine = index.as_chat_engine(chat_mode=\"condense_question\")\n",
    "    print(\"Index cleared and reset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd00a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ericmurray/repos/ai-agents-crash-course/notebooks_eric'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87630ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:02:58,799 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5 documents from ./data/\n"
     ]
    }
   ],
   "source": [
    "add_directory('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48dc1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf9e8616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_chunks': 5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cbd8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, top_k: int = 5):\n",
    "    \"\"\"Search for similar documents.\"\"\"\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    nodes = retriever.retrieve(query)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    for i, node in enumerate(nodes):\n",
    "        print(f\"--- Result {i+1} (score: {node.score:.4f}) ---\")\n",
    "        print(f\"Source: {node.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"Preview: {node.text[:]}...\\n\")\n",
    "    \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a688bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 11:05:40,658 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: where is Eric go to college?\n",
      "\n",
      "--- Result 1 (score: 0.2748) ---\n",
      "Source: Unknown\n",
      "Preview: 2004 - October 2012 (8 years)\n",
      "Chantilly, Virginia\n",
      "Responsible for expanding business with existing customers and contracts.\n",
      "Managed all other government agency contracts, Technical Lead  for satellite\n",
      "software  development projects, and lead for company IRAD/internal projects.  \n",
      "AGI\n",
      "Systems Engineer\n",
      "December 2003 - December 2004 (1 year 1 month)\n",
      "Pre and post sales responsibility for various government agencies. \n",
      "BAE Systems\n",
      "Modeling and Simualtions Engineer\n",
      "December 2002 - December 2003 (1 year 1 month)\n",
      "Modeling and Simulation development and projects using discrete event\n",
      "simulators, STK and MS Office tools. \n",
      "Adroit\n",
      "Engineer\n",
      "2000 - 2002 (2 years)\n",
      "Technical lead on R&D project supporting Air Force collection and exploitation\n",
      "systems\n",
      "Education\n",
      "University of Virginia\n",
      "BS, Mechanical Engineering · (1996 - 2000)\n",
      "North Carolina State University\n",
      "Masters of Engineering  · (2002 - 2005)\n",
      "  Page 3 of 3...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='b99ce0a3-baa2-46a1-835c-18a16620ade7', embedding=None, metadata={'page_label': '3', 'file_name': 'linkedin profile.pdf', 'file_path': '/Users/ericmurray/repos/ai-agents-crash-course/notebooks_eric/data/linkedin profile.pdf', 'file_type': 'application/pdf', 'file_size': 58940, 'creation_date': '2025-08-19', 'last_modified_date': '2025-08-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d20398df-6132-41c8-9428-178af3efa65e', node_type='4', metadata={'page_label': '3', 'file_name': 'linkedin profile.pdf', 'file_path': '/Users/ericmurray/repos/ai-agents-crash-course/notebooks_eric/data/linkedin profile.pdf', 'file_type': 'application/pdf', 'file_size': 58940, 'creation_date': '2025-08-19', 'last_modified_date': '2025-08-19'}, hash='0dc0b5728297494715f51d2386dc54e31263d729037922045db86d139f3af40f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='2004\\xa0-\\xa0October 2012\\xa0(8 years)\\nChantilly, Virginia\\nResponsible for expanding business with existing customers and contracts.\\nManaged all other government agency contracts, Technical Lead  for satellite\\nsoftware  development projects, and lead for company IRAD/internal projects.  \\nAGI\\nSystems Engineer\\nDecember 2003\\xa0-\\xa0December 2004\\xa0(1 year 1 month)\\nPre and post sales responsibility for various government agencies. \\nBAE Systems\\nModeling and Simualtions Engineer\\nDecember 2002\\xa0-\\xa0December 2003\\xa0(1 year 1 month)\\nModeling and Simulation development and projects using discrete event\\nsimulators, STK and MS Office tools. \\nAdroit\\nEngineer\\n2000\\xa0-\\xa02002\\xa0(2 years)\\nTechnical lead on R&D project supporting Air Force collection and exploitation\\nsystems\\nEducation\\nUniversity of Virginia\\nBS,\\xa0Mechanical Engineering\\xa0·\\xa0(1996\\xa0-\\xa02000)\\nNorth Carolina State University\\nMasters of Engineering\\xa0\\xa0·\\xa0(2002\\xa0-\\xa02005)\\n\\xa0 Page 3 of 3', mimetype='text/plain', start_char_idx=4, end_char_idx=907, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.2748052170916048)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"where is Eric go to college?\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960592b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
